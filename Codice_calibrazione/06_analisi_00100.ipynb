{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cee69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_dir = \"00_Input\"\n",
    "output_dir = \"01_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9420861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each file into its own DataFrame\n",
    "df_CALIB= pd.read_excel(os.path.join(output_dir, \"NETECH_CAMPIONE_CALIB.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ddf4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CALIB['CAUSALE ANALITICA'] = (df_CALIB['CAUSALE ANALITICA'].astype(str).str.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47fcd20",
   "metadata": {},
   "source": [
    "Applying the filters of the perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2c257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3178, 47)\n",
      "(3094, 47)\n",
      "(682, 47)\n"
     ]
    }
   ],
   "source": [
    "# da eliminare quando flg_SCEN_IN_USO != 1\n",
    "print(df_CALIB.shape)\n",
    "\n",
    "df_CALIB_ = df_CALIB[df_CALIB['flg_SCEN_IN_USO'] == 1]\n",
    "print(df_CALIB_.shape)\n",
    "\n",
    "df_CALIB_ = df_CALIB_[df_CALIB_[\"DESCRIZIONE\"] == \"Versamento giornaliero di importo contante elevato per la causale ed il soggetto\"]\n",
    "print(df_CALIB_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f949296",
   "metadata": {},
   "source": [
    "Analize classe di rischio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a509b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Classe",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "e63405f7-72f9-4327-9f27-37c3b06b6745",
       "rows": [
        [
         "Classe di rischio 3",
         "256"
        ],
        [
         "Classe di rischio 1",
         "158"
        ],
        [
         "Classe di rischio 5",
         "117"
        ],
        [
         "Classe di rischio 6",
         "55"
        ],
        [
         "Classe di rischio 7",
         "54"
        ],
        [
         "Classe di rischio 2",
         "22"
        ],
        [
         "Classe di rischio 4",
         "20"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "Classe\n",
       "Classe di rischio 3    256\n",
       "Classe di rischio 1    158\n",
       "Classe di rischio 5    117\n",
       "Classe di rischio 6     55\n",
       "Classe di rischio 7     54\n",
       "Classe di rischio 2     22\n",
       "Classe di rischio 4     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CALIB_[\"Classe\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95eb7d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "CAUSALE ANALITICA",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "89d7b0f8-d4f2-42b2-b356-b0535314a447",
       "rows": [
        [
         "03 - Versamento contante cassa continua",
         "334"
        ],
        [
         "D1 - Versamento di contante",
         "194"
        ],
        [
         "VV",
         "154"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "CAUSALE ANALITICA\n",
       "03 - Versamento contante cassa continua    334\n",
       "D1 - Versamento di contante                194\n",
       "VV                                         154\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CALIB_[\"CAUSALE ANALITICA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a37d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CALIB_[\"IMPORTO\"] = df_CALIB_[\"IMPORTO\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60b9623c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "flag_stato",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b79c4a52-f836-4807-80db-d44d45d0cf33",
       "rows": [
        [
         "0.0",
         "381"
        ],
        [
         "1.0",
         "301"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "flag_stato\n",
       "0.0    381\n",
       "1.0    301\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CALIB_[\"flag_stato\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c48c5",
   "metadata": {},
   "source": [
    "Filter for false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ff8ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 47)\n"
     ]
    }
   ],
   "source": [
    "df_CALIB_FP = df_CALIB_[df_CALIB_['flag_stato'] == 0]\n",
    "print(df_CALIB_FP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caaf7ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Classe",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "869d6826-0818-4e03-b9a7-24bdfd15e5ba",
       "rows": [
        [
         "Classe di rischio 3",
         "151"
        ],
        [
         "Classe di rischio 5",
         "82"
        ],
        [
         "Classe di rischio 1",
         "81"
        ],
        [
         "Classe di rischio 6",
         "36"
        ],
        [
         "Classe di rischio 7",
         "12"
        ],
        [
         "Classe di rischio 4",
         "11"
        ],
        [
         "Classe di rischio 2",
         "8"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "Classe\n",
       "Classe di rischio 3    151\n",
       "Classe di rischio 5     82\n",
       "Classe di rischio 1     81\n",
       "Classe di rischio 6     36\n",
       "Classe di rischio 7     12\n",
       "Classe di rischio 4     11\n",
       "Classe di rischio 2      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CALIB_FP[\"Classe\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7de7a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "CAUSALE ANALITICA",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "99711003-a30d-4ce8-933d-b1b10cbadb67",
       "rows": [
        [
         "03 - Versamento contante cassa continua",
         "171"
        ],
        [
         "D1 - Versamento di contante",
         "133"
        ],
        [
         "VV",
         "77"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "CAUSALE ANALITICA\n",
       "03 - Versamento contante cassa continua    171\n",
       "D1 - Versamento di contante                133\n",
       "VV                                          77\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CALIB_FP[\"CAUSALE ANALITICA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd42466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def _pct_labels(percentiles: List[float]) -> List[str]:\n",
    "    \"\"\"Helper to build column labels like Percentile_00, Percentile_05, , Percentile_100.\"\"\"\n",
    "    return [f\"Percentile_{int(round(q * 100)):02d}\" for q in percentiles]\n",
    "\n",
    "def compute_group_percentiles(\n",
    "    df: pd.DataFrame,\n",
    "    value_col: str,\n",
    "    group_cols: List[str],\n",
    "    percentiles: List[float],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute specified percentiles of `value_col` within each group in `group_cols`.\n",
    "    Returns a DataFrame with one row per group and one column per percentile cutoff.\n",
    "    \"\"\"\n",
    "    tmp = df.copy()\n",
    "    tmp[value_col] = pd.to_numeric(tmp[value_col], errors=\"coerce\")\n",
    "\n",
    "    # group-by quantiles → MultiIndex (group, percentile) → unstack to columns\n",
    "    q_tbl = (\n",
    "        tmp.groupby(group_cols)[value_col]\n",
    "           .quantile(percentiles)\n",
    "           .unstack()  # columns are the percentile floats\n",
    "           .reset_index()\n",
    "    )\n",
    "\n",
    "    # rename percentile columns (floats) to labels like p05, p10, ...\n",
    "    rename_map = {q: lbl for q, lbl in zip(q_tbl.columns[len(group_cols):], _pct_labels(percentiles))}\n",
    "    q_tbl = q_tbl.rename(columns=rename_map)\n",
    "\n",
    "    return q_tbl\n",
    "\n",
    "\n",
    "def apply_group_percentile_flags(\n",
    "    df: pd.DataFrame,\n",
    "    percentiles_df: pd.DataFrame,\n",
    "    value_col: str,\n",
    "    group_cols: List[str],\n",
    "    flag_operator: str = \">=\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge group percentile cutoffs into `df` and add 1/0 flags for each cutoff.\n",
    "    Flag is 1 if `value_col` {operator} cutoff (per row's group), else 0.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    out[value_col] = pd.to_numeric(out[value_col], errors=\"coerce\")\n",
    "\n",
    "    # Merge cutoffs on group columns (one-time join, avoids repeated transform calls)\n",
    "    out = out.merge(percentiles_df, how=\"left\", on=group_cols)\n",
    "\n",
    "    # Identify percentile columns we just merged (those starting with 'Percentile_')\n",
    "    pct_cols = [c for c in out.columns if c.startswith(\"Percentile_\")]\n",
    "   \n",
    "    # Build flags\n",
    "    if flag_operator == \">=\":\n",
    "        for c in pct_cols:\n",
    "            out[f\"flag_{c}\"] = (out[value_col] >= out[c]).astype(int)\n",
    "    elif flag_operator == \">\":\n",
    "        for c in pct_cols:\n",
    "            out[f\"flag_{c}\"] = (out[value_col] > out[c]).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"flag_operator must be '>' or '>='\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7662f3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(682, 89)\n"
     ]
    }
   ],
   "source": [
    "percentiles = [0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45,\n",
    "               0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1]\n",
    "\n",
    "# 1) compute group cutoffs\n",
    "cutoffs = compute_group_percentiles(\n",
    "    df=df_CALIB_FP,\n",
    "    value_col=\"IMPORTO\",\n",
    "    group_cols=[\"Classe\"],   # use your exact column names\n",
    "    percentiles=percentiles\n",
    ")\n",
    "\n",
    "# 2) apply flags using those cutoffs\n",
    "df_CALIB_threshold = apply_group_percentile_flags(\n",
    "    df=df_CALIB_,\n",
    "    percentiles_df=cutoffs,\n",
    "    value_col=\"IMPORTO\",\n",
    "    group_cols=[\"Classe\"],\n",
    "    flag_operator=\">=\"  # or \">\"\n",
    ")\n",
    "\n",
    "print(df_CALIB_threshold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "414e9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_dir, \"analisi_00100_risultati.xlsx\")\n",
    "# Export DataFrame to Excel\n",
    "df_CALIB_threshold.to_excel(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
