{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_dir = \"00_Input\"\n",
    "output_dir = \"01_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each file into its own DataFrame\n",
    "df_CALIB= pd.read_excel(os.path.join(output_dir, \"NETECH_CAMPIONE_CALIB.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CALIB['CAUSALE ANALITICA'] = (df_CALIB['CAUSALE ANALITICA'].astype(str).str.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47fcd20",
   "metadata": {},
   "source": [
    "Applying the filters of the perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da eliminare quando flg_SCEN_IN_USO != 1\n",
    "\n",
    "print(df_CALIB.shape)\n",
    "\n",
    "df_CALIB_ = df_CALIB[df_CALIB['flg_SCEN_IN_USO'] == 1]\n",
    "print(df_CALIB_.shape)\n",
    "\n",
    "df_CALIB_ = df_CALIB_[df_CALIB_[\"DESCRIZIONE\"] == \"Operazioni con paese controparte ad altissimo rischio\"]\n",
    "print(df_CALIB_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0cf160",
   "metadata": {},
   "source": [
    "Changing the type to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CALIB_[\"IMPORTO\"] = df_CALIB_[\"IMPORTO\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CALIB_[\"flag_stato\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a91fcf",
   "metadata": {},
   "source": [
    "Assume missing stato as open alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CALIB_.loc[df_CALIB_[\"flag_stato\"].isna(), \"flag_stato\"] = 1\n",
    "df_CALIB_[\"flag_stato\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c48c5",
   "metadata": {},
   "source": [
    "Filter for false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ff8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CALIB_FP = df_CALIB_[df_CALIB_['flag_stato'] == 0]\n",
    "print(df_CALIB_FP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd42466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def _pct_labels(percentiles: List[float]) -> List[str]:\n",
    "    \"\"\"Helper to build column labels like Percentile_00, Percentile_05, , Percentile_100.\"\"\"\n",
    "    return [f\"Percentile_{int(round(q * 100)):02d}\" for q in percentiles]\n",
    "\n",
    "def compute_group_percentiles(\n",
    "    df: pd.DataFrame,\n",
    "    value_col: str,\n",
    "    group_cols: List[str],\n",
    "    percentiles: List[float],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute specified percentiles of `value_col` within each group in `group_cols`.\n",
    "    Returns a DataFrame with one row per group and one column per percentile cutoff.\n",
    "    \"\"\"\n",
    "    tmp = df.copy()\n",
    "    tmp[value_col] = pd.to_numeric(tmp[value_col], errors=\"coerce\")\n",
    "\n",
    "    # group-by quantiles → MultiIndex (group, percentile) → unstack to columns\n",
    "    q_tbl = (\n",
    "        tmp.groupby(group_cols)[value_col]\n",
    "           .quantile(percentiles)\n",
    "           .unstack()  # columns are the percentile floats\n",
    "           .reset_index()\n",
    "    )\n",
    "\n",
    "    # rename percentile columns (floats) to labels like p05, p10, ...\n",
    "    rename_map = {q: lbl for q, lbl in zip(q_tbl.columns[len(group_cols):], _pct_labels(percentiles))}\n",
    "    q_tbl = q_tbl.rename(columns=rename_map)\n",
    "\n",
    "    return q_tbl\n",
    "\n",
    "\n",
    "def apply_group_percentile_flags(\n",
    "    df: pd.DataFrame,\n",
    "    percentiles_df: pd.DataFrame,\n",
    "    value_col: str,\n",
    "    group_cols: List[str],\n",
    "    flag_operator: str = \">=\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge group percentile cutoffs into `df` and add 1/0 flags for each cutoff.\n",
    "    Flag is 1 if `value_col` {operator} cutoff (per row's group), else 0.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    out[value_col] = pd.to_numeric(out[value_col], errors=\"coerce\")\n",
    "\n",
    "    # Merge cutoffs on group columns (one-time join, avoids repeated transform calls)\n",
    "    out = out.merge(percentiles_df, how=\"left\", on=group_cols)\n",
    "\n",
    "    # Identify percentile columns we just merged (those starting with 'Percentile_')\n",
    "    pct_cols = [c for c in out.columns if c.startswith(\"Percentile_\")]\n",
    "   \n",
    "    # Build flags\n",
    "    if flag_operator == \">=\":\n",
    "        for c in pct_cols:\n",
    "            out[f\"flag_{c}\"] = (out[value_col] >= out[c]).astype(int)\n",
    "    elif flag_operator == \">\":\n",
    "        for c in pct_cols:\n",
    "            out[f\"flag_{c}\"] = (out[value_col] > out[c]).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"flag_operator must be '>' or '>='\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = [0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45,\n",
    "               0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1]\n",
    "\n",
    "# 1) compute group cutoffs\n",
    "cutoffs = compute_group_percentiles(\n",
    "    df=df_CALIB_FP,\n",
    "    value_col=\"IMPORTO\",\n",
    "    group_cols=[\"CAUSALE ANALITICA\"],   # use your exact column names\n",
    "    percentiles=percentiles\n",
    ")\n",
    "\n",
    "# 2) apply flags using those cutoffs\n",
    "df_CALIB_threshold = apply_group_percentile_flags(\n",
    "    df=df_CALIB_,\n",
    "    percentiles_df=cutoffs,\n",
    "    value_col=\"IMPORTO\",\n",
    "    group_cols=[\"CAUSALE ANALITICA\"],\n",
    "    flag_operator=\">=\"  # or \">\"\n",
    ")\n",
    "\n",
    "print(df_CALIB_threshold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_dir, \"analisi_00090_risultati.xlsx\")\n",
    "# Export DataFrame to Excel\n",
    "df_CALIB_threshold.to_excel(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
